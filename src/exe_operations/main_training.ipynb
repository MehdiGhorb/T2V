{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from tqdm import trange\n",
    "import torch\n",
    "\n",
    "from video_diffusion_pytorch import Unet3D, GaussianDiffusion\n",
    "\n",
    "# Import local modules\n",
    "sys.path.append('../helper')\n",
    "from dataLoader import read_data\n",
    "from trainingCheckPoint import getLatestCheckpoint\n",
    "\n",
    "sys.path.append('../tensorMaker')\n",
    "from saveTensor import loadTensor\n",
    "\n",
    "sys.path.append('../common')\n",
    "import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read Training Text Data'''\n",
    "training_rows = read_data(os.path.join(paths.base_data_dir + '/csv_files/customised', args.csv_file_path))\n",
    "train_text = []\n",
    "# Read video descriptions\n",
    "for index in training_rows:\n",
    "    train_text.append(index[1])\n",
    "# Delete for memory efficiency purposes\n",
    "del training_rows\n",
    "# garbage collector (Test if this command really helps improve memory efficiency)\n",
    "\n",
    "'''Read Validation Text Data'''\n",
    "validation_rows = read_data(os.path.join(paths.base_data_dir + '/csv_files/customised', args.csv_file_path.replace(\"_train\", \"_val\")))\n",
    "val_text = []\n",
    "# Read video descriptions\n",
    "for index in validation_rows:\n",
    "    val_text.append(index[1])\n",
    "# Delete for memory efficiency purposes\n",
    "del validation_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Training Tensor'''\n",
    "training_yaml = args.csv_file_path.replace(\"customised\", \"training\").replace(\"_train.csv\", \".yaml\")\n",
    "last_checkpoint = getLatestCheckpoint(os.path.join(paths.training_checkpoint_dir + f'/{args.csv_file_path.replace(\"_train.csv\", \"\")}', training_yaml))\n",
    "FolderPath = f'/{args.csv_file_path.replace(\".csv\", \"\")}'\n",
    "train_tensor = loadTensor(os.path.join(paths.tensor_path + FolderPath, f'track_{last_checkpoint}.pt'))\n",
    "print(\"\\nTraining Tensor has been loaded successfully!!\\n\")\n",
    "\n",
    "'''Load Validation Tensor'''\n",
    "# Assuming there is only one Tensor for Validation (If running out of Memory, simply devide the Tensor in smaller Tnsors and randomly choose one of them)\n",
    "FolderPath = f'/{args.csv_file_path.replace(\"_train.csv\", \"_val\")}'\n",
    "val_tensor = loadTensor(os.path.join(paths.tensor_path + FolderPath, 'track_0.pt'))\n",
    "print(\"\\nValidation Tensor has been loaded successfully!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training iterations\n",
    "num_iterations = 100\n",
    "batch_size = 1\n",
    "checkpoint_interval = 80\n",
    "checkpoint_path = os.path.join(paths.model_dir, 'main_model.pth')\n",
    "dataset_size = 9  # Number of training videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model'''\n",
    "model = Unet3D(\n",
    "    dim=64,\n",
    "    use_bert_text_cond=True,  # this must be set to True to auto-use the bert model dimensions\n",
    "    dim_mults=(1, 2, 4, 8),\n",
    ")\n",
    "\n",
    "# Load the latest model\n",
    "if last_checkpoint != 0: \n",
    "    model.load_state_dict(torch.load(os.path.join(paths.model_dir, 'main_model.pth')))\n",
    "    model.train()  # Set the model in training mode\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size=64,    # height and width of frames\n",
    "    num_frames=10,    # number of video frames\n",
    "    timesteps=1000,   # number of steps\n",
    "    loss_type='l1'    # L1 or L2\n",
    ")\n",
    "\n",
    "# Assuming you have your optimizer defined\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in trange(num_iterations):\n",
    "\n",
    "    # Sample indices for the current batch\n",
    "    batch_indices = torch.randint(0, dataset_size, (batch_size,))\n",
    "        \n",
    "    # Sample a batch of training data\n",
    "    batch_videos = train_tensor[batch_indices]\n",
    "    batch_text = [train_text[idx] for idx in batch_indices]\n",
    "\n",
    "    # Forward pass with text conditioning\n",
    "    loss = diffusion(batch_videos, cond=batch_text)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Iteration [{iteration}]: Loss = {loss.item()}\")\n",
    "    if iteration % 100 == 0:\n",
    "        print(f\"Train Iteration [{iteration}/{num_iterations}]: Loss = {loss.item()}\")\n",
    "            \n",
    "    # Validation every checkpoint_interval iterations\n",
    "    if (iteration + 1) % checkpoint_interval == 0:\n",
    "        val_loss = 0.0\n",
    "        num_val_batches = len(val_tensor) // batch_size\n",
    "\n",
    "        for val_batch_start in range(0, len(val_tensor), batch_size):\n",
    "            val_batch_videos = val_tensor[val_batch_start:val_batch_start + batch_size]\n",
    "            val_batch_text = val_text[val_batch_start:val_batch_start + batch_size]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                val_batch_loss = diffusion(val_batch_videos, cond=val_batch_text)\n",
    "                val_loss += val_batch_loss.item()\n",
    "\n",
    "        val_loss /= num_val_batches\n",
    "        print(f\"Validation Iteration [{iteration}/{num_iterations}]: Loss = {val_loss}\")\n",
    "            \n",
    "        # Save checkpoint\n",
    "        torch.save({\n",
    "            'iteration': iteration,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'val_loss': val_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at iteration {iteration + 1}\")\n",
    "\n",
    "# Update the training Checkpoint\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
